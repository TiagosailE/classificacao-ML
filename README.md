# üìå Classifica√ß√£o com Machine Learning ‚Äì Dataset Breast Cancer

## üë®‚Äçüè´ Disciplina
Intelig√™ncia Artificial  
Professor: Ronierison de Souza Maciel  
Aluno: Tiago Elias dos Santos 
Curso: Sistemas de Informa√ß√£o ‚Äì VI Per√≠odo, Noturno  

---

## üéØ Objetivo da Atividade
Implementar e comparar algoritmos de classifica√ß√£o supervisionada utilizando um dataset real, aplicando t√©cnicas de pr√©-processamento, modelagem e avalia√ß√£o de desempenho.

---

## üìä Dataset Escolhido
- **Fonte:** `sklearn.datasets.load_breast_cancer`  
- **Descri√ß√£o:** O dataset cont√©m caracter√≠sticas de tumores de mama, utilizados para prever se s√£o **malignos (1)** ou **benignos (0)**.  
- **Tamanho:** 569 amostras √ó 30 features.  
- **Vari√°vel alvo:** diagn√≥stico (`maligno` ou `benigno`).  
- **Features:** raio, textura, per√≠metro, √°rea, suavidade, compacidade, concavidade, simetria, entre outros.  

**Justificativa da escolha:**  
√â um dataset cl√°ssico e muito utilizado em Machine Learning. Ele √© balanceado, tem apenas duas classes (classifica√ß√£o bin√°ria), e cont√©m vari√°veis num√©ricas que permitem aplicar diferentes algoritmos.

---

## ‚öôÔ∏è Etapas Realizadas
### üîπ 4.2 ‚Äì Prepara√ß√£o dos Dados
- Carregamento e explora√ß√£o inicial (`head`, `info`, `describe`).  
- Separa√ß√£o entre atributos (`X`) e vari√°vel alvo (`y`).  
- Divis√£o em treino e teste com `train_test_split`.  

### üîπ 4.3 ‚Äì Modelagem
Foram treinados e avaliados tr√™s algoritmos:
- DecisionTreeClassifier  
- KNeighborsClassifier  
- LogisticRegression  

M√©tricas avaliadas:
- Acur√°cia  
- Precis√£o  
- Recall  
- F1-score  
- Matriz de confus√£o  

Foi gerado tamb√©m um **gr√°fico comparativo de acur√°cia** entre os modelos.

### üîπ 4.4 ‚Äì Conclus√£o
O modelo com melhor desempenho foi a **Logistic Regression**, que atingiu a maior acur√°cia entre os tr√™s algoritmos.  
Esse resultado faz sentido, pois o dataset √© relativamente bem separado linearmente, o que favorece modelos lineares.  

Poss√≠veis melhorias:
- Aplicar normaliza√ß√£o dos dados (melhora o desempenho do KNN).  
- Realizar tuning de hiperpar√¢metros (GridSearchCV ou RandomizedSearchCV).  
- Testar outros algoritmos, como Random Forest e SVM.  

---

## üìà Resultados Obtidos (exemplo)
- **Decision Tree:** Acur√°cia ‚âà 0.91  
- **KNN:** Acur√°cia ‚âà 0.88  
- **Logistic Regression:** Acur√°cia ‚âà 0.95  

> ‚ö†Ô∏è Os valores podem variar um pouco devido √† aleatoriedade da divis√£o entre treino e teste.


