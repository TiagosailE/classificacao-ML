# ğŸ“Š ClassificaÃ§Ã£o com Machine Learning â€“ Dataset Breast Cancer

## ğŸ‘¤ Autor
- Nome: Tiago Elias dos Santos Jovencio
- Disciplina: InteligÃªncia Artificial
- Professor: Ronierison de Souza Maciel
- Curso: Sistemas de InformaÃ§Ã£o â€“ VI PerÃ­odo, Noturno

---

## ğŸ¯ Objetivo da Atividade
Implementar e comparar algoritmos de **classificaÃ§Ã£o supervisionada** utilizando um dataset real, aplicando:
- PrÃ©-processamento
- Modelagem
- AvaliaÃ§Ã£o de desempenho

Os resultados devem ser versionados em um repositÃ³rio no GitHub, com commits graduais e descritivos.

---

## ğŸ“‚ Dataset Utilizado
- Fonte: `sklearn.datasets.load_breast_cancer`
- Tamanho: **569 amostras Ã— 30 features**
- VariÃ¡vel alvo: diagnÃ³stico do tumor (`0 = maligno`, `1 = benigno`)
- Features: medidas obtidas de exames de mama (raio mÃ©dio, textura, perÃ­metro, Ã¡rea, suavidade etc.)

**Justificativa da escolha:**  
Ã‰ um dataset clÃ¡ssico, balanceado e de tamanho adequado para experimentos de aprendizado de mÃ¡quina supervisionado.

---

## âš™ï¸ Modelos de ClassificaÃ§Ã£o
Foram testados trÃªs algoritmos:

1. **Decision Tree**  
2. **K-Nearest Neighbors (KNN)**  
3. **Logistic Regression**  

---

## ğŸ“ˆ Resultados Obtidos

### MÃ©tricas principais (dados de teste)
| Modelo               | AcurÃ¡cia | PrecisÃ£o | Recall | F1-Score |
|----------------------|----------|----------|--------|----------|
| Decision Tree        | ~0.918   | ~0.919   | ~0.918 | ~0.918   |
| KNN                  | ~0.930   | ~0.931   | ~0.930 | ~0.930   |
| Logistic Regression  | ~0.959   | ~0.960   | ~0.959 | ~0.959   |

### ComparaÃ§Ã£o de acurÃ¡cia
O grÃ¡fico gerado no notebook mostra que **Logistic Regression** obteve o melhor desempenho.

---

## ğŸ“ ConclusÃ£o
- O melhor modelo foi a **RegressÃ£o LogÃ­stica**, com maior acurÃ¡cia.  
- Isso faz sentido, pois o dataset Ã© majoritariamente linearmente separÃ¡vel.  
- O KNN teve desempenho prÃ³ximo, mas poderia melhorar com normalizaÃ§Ã£o dos dados.  
- Ãrvores de decisÃ£o tambÃ©m se saÃ­ram bem, mas com menor precisÃ£o.  

**PossÃ­veis melhorias:**
- NormalizaÃ§Ã£o das features (especialmente Ãºtil para KNN).  
- Ajuste de hiperparÃ¢metros via Grid Search.  
- Testar outros algoritmos, como Random Forest ou SVM.  

